{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc99df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a977aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pywin32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4aef7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18835e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dfae26",
   "metadata": {},
   "source": [
    "# Exercise 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e0202",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;\">To count the number of cars going to the city centre, I have implemented something called a box-point-collision. The way the collision algorithm works, is that for a car's top left corner coordinates, if those coordinates \"collide\" or fall within the box, it will count as a collision and increase the counter by 1. The placement of the box is also very important as it has to be at an area where no other cars would be able to invoke the algorithm.</p>\n",
    "\n",
    "<p style=\"font-size:14px; color:red;\">The function will contain comments to explain the code more in-depth.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eccdf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd1d261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collision(x, y, bx1, by1, bx2, by2):\n",
    "    # check if the point lies between the box's coordinates, if yes, return True, if no, return False\n",
    "    if x >= bx1 and x <= bx2 and y >= by1 and y <= by2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27afe944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection(file):\n",
    "    # collision box coordinates\n",
    "    box_x1 = 561\n",
    "    box_x2 = 567\n",
    "    box_y1 = 101\n",
    "    box_y2 = 139\n",
    "    # global counter\n",
    "    counter = 0\n",
    "    # create VideoCapture object and read frames from input file\n",
    "    video = cv2.VideoCapture(file)\n",
    "    # check if video opened successfully\n",
    "    if (video.isOpened()== False):\n",
    "        print(\"Error opening video file.\")\n",
    "    else:\n",
    "        print(\"Video opened successfully!\")\n",
    "    # global baseline\n",
    "    initial_frame = None\n",
    "    # loop until video completes\n",
    "    while True:\n",
    "        # capture frame-by-frame\n",
    "        check, frame = video.read()\n",
    "        # if there are no more frames to read, exit\n",
    "        if frame is None:\n",
    "            break\n",
    "        # option to exit with 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "            \n",
    "        # [600, 1040] is the height and width of the video\n",
    "        # we are only interested in the main road which is bound to [265:, 0:]\n",
    "        main_road = frame[265:600, 0:1040]\n",
    "        # draw a line to separate the video and main road\n",
    "        cv2.line(frame, (0, 260), (1040, 260), (0, 0, 255), 5, 8, 0)\n",
    "        \n",
    "        # gray conversion\n",
    "        gray_frame = cv2.cvtColor(main_road, cv2.COLOR_BGR2GRAY)\n",
    "        # set first captured frame as the baseline\n",
    "        if initial_frame is None:\n",
    "            initial_frame = gray_frame\n",
    "        # find the difference of the current frame from the baseline \n",
    "        delta_frame = cv2.absdiff(initial_frame, gray_frame)\n",
    "        # if a pixel value is more than 40, assign it to 255\n",
    "        _, threshold_frame = cv2.threshold(delta_frame, 30, 255, cv2.THRESH_BINARY)\n",
    "        # noise reduction\n",
    "        blur_frame = cv2.GaussianBlur(threshold_frame, (5, 5), 0)\n",
    "        # this is the \"collision box\" where we check if cars \"collide with\"\n",
    "        cv2.rectangle(main_road, (box_x1, box_y1), (box_x2, box_y2), (0, 255, 255), 1)\n",
    "        \n",
    "        # identify all the contours in the video\n",
    "        (contours, _) = cv2.findContours(blur_frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for c in contours:\n",
    "            # if the contour area is more than a certain value, draw a rectangle around it\n",
    "            if cv2.contourArea(c) > 3000:\n",
    "                x, y, w, h, = cv2.boundingRect(c)\n",
    "                cv2.rectangle(main_road, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "                # draw a tracking point of top left corner of bounding box\n",
    "                cv2.circle(main_road, (x, y), 1, (0, 0, 255), 2)\n",
    "                # using the tracking point coordinates, check if they collide with the box\n",
    "                # if True, increment counter by 1\n",
    "                hit = collision(x, y, box_x1, box_y1, box_x2, box_y2)\n",
    "                if hit:\n",
    "                    counter += 1\n",
    "        \n",
    "        # write counter\n",
    "        cv2.putText(frame, (\"Number of cars going to the city centre: \" + str(counter)), (10, 240), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "        # show video\n",
    "        cv2.imshow(\"CCTV\", frame)\n",
    "        \n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Number of cars going to the city centre:\", counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d5cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened successfully!\n",
      "Number of cars going to the city centre: 6\n"
     ]
    }
   ],
   "source": [
    "object_detection('Exercise1_Files/Traffic_Laramie_1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2d068c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened successfully!\n",
      "Number of cars going to the city centre: 4\n"
     ]
    }
   ],
   "source": [
    "object_detection('Exercise1_Files/Traffic_Laramie_2.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e395d",
   "metadata": {},
   "source": [
    "## References\n",
    "<ul>\n",
    "    <li>\n",
    "        <a href=https://www.coursera.org/learn/uol-cm3065-intelligent-signal-processing/ungradedLab/0PXRU/7-104-exercise-15-introduction-to-motion-detection-with-opencv-and-python/lab?path=%2Fnotebooks%2FExercises%2FExercise%252015.%2520Introduction%2520to%2520motion%2520detection%2520with%2520OpenCV%2520and%2520Python.ipynb>Coursera Lab</a>\n",
    "    </li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
